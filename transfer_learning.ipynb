{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Kk_VPL-qCkre",
        "HoM4F2K6-i8C",
        "fHchrm0kYEyj",
        "z1BAVOiu-yAa",
        "GLPdMFJm9Bln",
        "6PK7ZvwEx3qh",
        "5ztw2VjnwSO5"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev-kentayamada/machine-learning/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyKv3qcjEqkH"
      },
      "source": [
        "##パッケージのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9p0dHM_ErW5"
      },
      "source": [
        "!pip install -U tensorflow-addons\n",
        "!pip install -U plotly\n",
        "!pip install -U kaleido\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pytz\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import datetime\n",
        "import plotly.graph_objects as go\n",
        "from PIL import Image\n",
        "import plotly.express as px\n",
        "\n",
        "random.seed(0) #乱数シードを固定\n",
        "tf.random.set_seed(0) #乱数シードを固定"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLeZATVaNAnE"
      },
      "source": [
        "##TPUの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ga-Ibcdd_EY"
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime')\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1dN2Ms_niz5"
      },
      "source": [
        "##データセットの用意"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ92BMt3ElUJ"
      },
      "source": [
        "###ダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Km-4QEIEimu"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! mkdir /content/downloads\n",
        "! kaggle competitions download -c dogs-vs-cats -p /content/downloads\n",
        "! unzip /content/downloads/train.zip -d /content/downloads\n",
        "! unzip /content/downloads/test1.zip -d /content/downloads\n",
        "! rm kaggle.json /content/downloads/test1.zip /content/downloads/train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL0KQRsGLdpl"
      },
      "source": [
        "###整理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp146htILfte"
      },
      "source": [
        "import re\n",
        "import shutil\n",
        "\n",
        "train_downloads_dir = '/content/downloads/train'\n",
        "train_path_v1 = '/content/datasets/v1/train'\n",
        "val_path_v1 = '/content/datasets/v1/val'\n",
        "test_path_v1 = '/content/datasets/v1/test'\n",
        "train_path_v2 = '/content/datasets/v2/train'\n",
        "test_path_v2 = '/content/datasets/v2/test'\n",
        "\n",
        "all_imgs = os.listdir(train_downloads_dir)\n",
        "\n",
        "all_dogs = [train_all_img for train_all_img in all_imgs if re.match('dog', train_all_img)]\n",
        "all_cats = [train_all_img for train_all_img in all_imgs if re.match('cat', train_all_img)]\n",
        "\n",
        "# シャッフル\n",
        "random.shuffle(all_dogs)\n",
        "random.shuffle(all_cats)\n",
        "\n",
        "# v1\n",
        "# train_dogs[5000] test_dogs[6250] val_dogs[1250]\n",
        "# train_cats[5000] test_cats[6250] val_cats[1250]\n",
        "os.makedirs(f'{train_path_v1}/dogs', exist_ok=True)\n",
        "os.makedirs(f'{test_path_v1}/dogs', exist_ok=True)\n",
        "os.makedirs(f'{val_path_v1}/dogs', exist_ok=True)\n",
        "os.makedirs(f'{train_path_v1}/cats', exist_ok=True)\n",
        "os.makedirs(f'{test_path_v1}/cats', exist_ok=True)\n",
        "os.makedirs(f'{val_path_v1}/cats', exist_ok=True)\n",
        "\n",
        "for dog, cat in zip(all_dogs[:5000], all_cats[:5000]):\n",
        "  shutil.copy(f\"{train_downloads_dir}/{dog}\", f\"{train_path_v1}/dogs/{dog}\")\n",
        "  shutil.copy(f\"{train_downloads_dir}/{cat}\", f\"{train_path_v1}/cats/{cat}\")\n",
        "\n",
        "for dog, cat in zip(all_dogs[5000:11250], all_cats[5000:11250]):\n",
        "  shutil.copy(f\"{train_downloads_dir}/{dog}\", f\"{test_path_v1}/dogs/{dog}\")\n",
        "  shutil.copy(f\"{train_downloads_dir}/{cat}\", f\"{test_path_v1}/cats/{cat}\")\n",
        "\n",
        "for dog, cat in zip(all_dogs[11250:], all_cats[11250:]):\n",
        "  shutil.copy(f\"{train_downloads_dir}/{dog}\", f\"{val_path_v1}/dogs/{dog}\")\n",
        "  shutil.copy(f\"{train_downloads_dir}/{cat}\", f\"{val_path_v1}/cats/{cat}\")\n",
        "\n",
        "\n",
        "# v2\n",
        "# train_dogs[6250] train_cats[6250]\n",
        "# val_dogs[6250] val_cats[6250]\n",
        "os.makedirs(f'{train_path_v2}/dogs', exist_ok=True)\n",
        "os.makedirs(f'{train_path_v2}/cats', exist_ok=True)\n",
        "os.makedirs(f'{test_path_v2}/dogs', exist_ok=True)\n",
        "os.makedirs(f'{test_path_v2}/cats', exist_ok=True)\n",
        "\n",
        "for dog, cat in zip(all_dogs[:len(all_dogs)//2], all_cats[:len(all_cats)//2]):\n",
        "  shutil.copy(f\"{train_downloads_dir}/{dog}\", f\"{train_path_v2}/dogs/{dog}\")\n",
        "  shutil.copy(f\"{train_downloads_dir}/{cat}\", f\"{train_path_v2}/cats/{cat}\")\n",
        "\n",
        "for dog, cat in zip(all_dogs[len(all_dogs)//2:], all_cats[len(all_cats)//2:]):\n",
        "  shutil.copy(f\"{train_downloads_dir}/{dog}\", f\"{test_path_v2}/dogs/{dog}\")\n",
        "  shutil.copy(f\"{train_downloads_dir}/{cat}\", f\"{test_path_v2}/cats/{cat}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9hCC3KMBuVY"
      },
      "source": [
        "##変数の作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOt96U6WyVnW"
      },
      "source": [
        "import pathlib\n",
        "import glob\n",
        "\n",
        "v1_all_imgs_train = [str(path) for path in list(pathlib.Path(train_path_v1).glob('*/*'))]\n",
        "v1_all_imgs_val = [str(path) for path in list(pathlib.Path(val_path_v1).glob('*/*'))]\n",
        "v1_all_imgs_test = [str(path) for path in list(pathlib.Path(test_path_v1).glob('*/*'))]\n",
        "\n",
        "v2_all_imgs_train = [str(path) for path in list(pathlib.Path(train_path_v2).glob('*/*'))]\n",
        "v2_all_imgs_test = [str(path) for path in list(pathlib.Path(test_path_v2).glob('*/*'))]\n",
        "\n",
        "# シャッフル\n",
        "random.shuffle(v1_all_imgs_train)\n",
        "random.shuffle(v1_all_imgs_val)\n",
        "random.shuffle(v1_all_imgs_test)\n",
        "\n",
        "random.shuffle(v2_all_imgs_train)\n",
        "random.shuffle(v2_all_imgs_test)\n",
        "\n",
        "label_names = sorted(item.name for item in pathlib.Path(train_path_v1).glob('*/') if item.is_dir())\n",
        "label_to_index = dict((name, index) for index,name in enumerate(label_names))\n",
        "\n",
        "v1_all_labels_train = [label_to_index[pathlib.Path(path).parent.name] for path in v1_all_imgs_train]\n",
        "v1_all_labels_val = [label_to_index[pathlib.Path(path).parent.name] for path in v1_all_imgs_val]\n",
        "v1_all_labels_test = [label_to_index[pathlib.Path(path).parent.name] for path in v1_all_imgs_test]\n",
        "\n",
        "v2_all_labels_train = [label_to_index[pathlib.Path(path).parent.name] for path in v2_all_imgs_train]\n",
        "v2_all_labels_test = [label_to_index[pathlib.Path(path).parent.name] for path in v2_all_imgs_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_VPL-qCkre"
      },
      "source": [
        "##NPZデータセットの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0GpcQdb_Pe"
      },
      "source": [
        "IMG_SIZE = 96\n",
        "IMG_MODE = \"RGB\"\n",
        "\n",
        "x_train = [np.asarray(Image.open(img_train).convert(IMG_MODE).resize((IMG_SIZE, IMG_SIZE))) for img_train in v1_all_imgs_train]\n",
        "y_train = [label_train for label_train in v1_all_labels_train]\n",
        "\n",
        "x_val = [np.asarray(Image.open(img_test).convert(IMG_MODE).resize((IMG_SIZE, IMG_SIZE))) for img_test in v1_all_imgs_val]\n",
        "y_val = [label_test for label_test in v1_all_labels_val]\n",
        "\n",
        "x_test = [np.asarray(Image.open(img_test).convert(IMG_MODE).resize((IMG_SIZE, IMG_SIZE))) for img_test in v1_all_imgs_test]\n",
        "y_test = [label_test for label_test in v1_all_labels_test]\n",
        "\n",
        "#numpy配列に変換\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "#save\n",
        "np.savez(f'/content/datasets/v2/{IMG_SIZE}_{IMG_MODE}_catDog', x_train=x_train, y_train=y_train, x_val=x_val, y_val=y_val, x_test=x_test, y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoM4F2K6-i8C"
      },
      "source": [
        "##NPZデータセットを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57v8fBEABrqc"
      },
      "source": [
        "# npz ファイルからのロード\n",
        "data = np.load('/content/datasets/v2/96_RGB_catDog.npz')\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "x_val = data['x_val']\n",
        "y_val = data['y_val']\n",
        "x_test = data['x_test']\n",
        "y_test = data['y_test']\n",
        "\n",
        "# NumPy 配列をロード\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# データセットのシャッフルとバッチ化\n",
        "BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "def prepare(ds, shuffle=False, augment=False, one_hot=False):\n",
        "  if one_hot:\n",
        "    ds = ds.map(lambda image, label: (tf.cast(image, tf.float32) / 255.0, tf.cast(tf.one_hot(tf.cast(label, tf.int64), 2), tf.float32)), num_parallel_calls=AUTOTUNE)\n",
        "  else:\n",
        "    ds = ds.map(lambda image, label: (tf.cast(image, tf.float32) / 255.0, tf.cast(label, tf.float32)), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # キャシュ化する\n",
        "  # ds = ds.cache(filename='./cache.tf-data')\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(1000)\n",
        "\n",
        "  # Batch all datasets\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # Use data augmentation only on the training set\n",
        "  if augment:\n",
        "    ds = ds.map(lambda image, label: (data_augmentation(image, training=True), label), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # Use buffered prefecting on all datasets\n",
        "  return ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "train_ds_normal = prepare(train_ds, shuffle=True, augment=True)\n",
        "val_ds_normal = prepare(val_ds)\n",
        "test_ds_normal = prepare(test_ds)\n",
        "\n",
        "train_ds_categorical = prepare(train_ds, shuffle=True, augment=True, one_hot=True)\n",
        "val_ds_categorical = prepare(val_ds, one_hot=True)\n",
        "test_ds_categorical = prepare(test_ds, one_hot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2LC_j4GOScI"
      },
      "source": [
        "###可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oHPX2_jljkJ"
      },
      "source": [
        "def convert_ds(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "converted_ds = convert_ds(test_ds_categorical, 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKRFYlS4ShMg"
      },
      "source": [
        "CLASSES = ['Cat', 'Dog']\n",
        "\n",
        "# Re-run this cell to show a new batch of images\n",
        "images, classes = next(converted_ds)\n",
        "\n",
        "if isinstance(classes[0], np.ndarray):\n",
        "  class_idxs = np.argmax(classes, axis=-1) # transform from one-hot array to class number\n",
        "  labels = [CLASSES[idx] for idx in class_idxs]\n",
        "else:\n",
        "  labels = [CLASSES[int(idx)] for idx in classes]\n",
        "\n",
        "fig = px.imshow(np.squeeze(np.array(images)), facet_col=0, facet_col_wrap=3)\n",
        "fig.for_each_annotation(lambda a: a.update(text=(labels[int(a.text.split(\"=\")[-1])])))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv8DfWBI_Ck8"
      },
      "source": [
        "##直接データセットを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu_GvCqxzoYy"
      },
      "source": [
        "# 検証用のtf.data.Datasetを作成\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = 160\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_path_v2,\n",
        "    validation_split=0.2,\n",
        "    seed = 123,\n",
        "    subset=\"training\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE)\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_path_v2,\n",
        "    validation_split=0.2,\n",
        "    seed = 123,\n",
        "    subset=\"validation\",\n",
        "    image_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_path_v2,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=(IMG_SIZE, IMG_SIZE)\n",
        ")\n",
        "\n",
        "# バッファリングされたプリフェッチを使用して、I / Oがブロックされることなくディスクからイメージをロード\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgc2FZKVMx15"
      },
      "source": [
        "##モデルを構築する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSBGwNsWgBx-"
      },
      "source": [
        "###TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHchrm0kYEyj"
      },
      "source": [
        "####モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSX3zXBDgDIf",
        "collapsed": true
      },
      "source": [
        "DATE_TIME = datetime.datetime.now(pytz.timezone('Asia/Tokyo')).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "\n",
        "DIR_MODEL_1 = f\"saved_models/TPU/model_1/{DATE_TIME}\"\n",
        "DIR_MODEL_2 = f\"saved_models/TPU/model_2/{DATE_TIME}\"\n",
        "DIR_MODEL_3 = f\"saved_models/TPU/model_3/{DATE_TIME}\"\n",
        "\n",
        "def create_model(model_number):\n",
        "  if model_number == 1:\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=x_train.shape[1:], include_top=False, weights='imagenet', pooling='avg')\n",
        "    base_model.trainable = False\n",
        "    model = tf.keras.Sequential([\n",
        "                                base_model,\n",
        "                                tf.keras.layers.Dropout(0.5),\n",
        "                                tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "  elif model_number == 2:\n",
        "    base_model = tf.keras.applications.EfficientNetB7(input_shape=x_train.shape[1:], include_top=False, weights='imagenet', pooling='avg')\n",
        "    base_model.trainable = False\n",
        "    model = tf.keras.Sequential([\n",
        "                                base_model,\n",
        "                                tf.keras.layers.Dense(len(set(y_train)), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "  elif model_number == 3:\n",
        "    base_model = tf.keras.applications.Xception(input_shape=x_train.shape[1:], include_top=False)\n",
        "    base_model.trainable = False\n",
        "    model = tf.keras.Sequential([\n",
        "                                base_model,\n",
        "                                tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                tf.keras.layers.Dense(len(set(y_train)), activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "  else:\n",
        "    print('Error: Not Defined', file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "def plot_history(hist, test_acc):\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, len(hist.epoch)+1, 1), y=hist.history['loss'], name=\"train_loss\", line = dict(color='royalblue', dash='dash')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, len(hist.epoch)+1, 1), y=hist.history['val_loss'], name=\"val_loss\", line = dict(color='firebrick', dash='dot')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, len(hist.epoch)+1, 1), y=hist.history['accuracy'], name=\"train_acc\", line=dict(color='royalblue')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, len(hist.epoch)+1, 1), y=hist.history['val_accuracy'], name=\"val_acc\", line=dict(color='firebrick')))\n",
        "  fig.update_layout(\n",
        "      xaxis=dict(dtick=1),\n",
        "      title=f'Loss: {round(test_acc[0], 4)} / Accurecy: {round(test_acc[1]*100)}%',\n",
        "      title_x=0.5,\n",
        "      xaxis_title='Epoch',\n",
        "      yaxis_title='Loss/Accuracy'\n",
        "  )\n",
        "  fig.show()\n",
        "\n",
        "  return fig\n",
        "\n",
        "\n",
        "def train(model_number, num_epochs, plot):\n",
        "  default_callback = [\n",
        "                      tfa.callbacks.TQDMProgressBar(),\n",
        "                      # tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=3, verbose=1\n",
        "  ]\n",
        "  \n",
        "  if model_number == 1:\n",
        "    # モデルをトレーニングする\n",
        "    hist = model.fit(\n",
        "        train_ds_normal,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_ds_normal,\n",
        "        callbacks=default_callback,\n",
        "        verbose=0\n",
        "    )\n",
        "    # SAVE\n",
        "    os.makedirs(f'{DIR_MODEL_1}', exist_ok=True)\n",
        "    model.save(f'{DIR_MODEL_1}/model.h5')\n",
        "\n",
        "    # Evaluate\n",
        "    test_acc = model.evaluate(test_ds_normal, callbacks=default_callback, verbose=0)\n",
        "\n",
        "    if plot: plot_history(hist, test_acc).write_image(f\"{DIR_MODEL_1}/model.png\")\n",
        "\n",
        "  elif model_number == 2:\n",
        "    # モデルをトレーニングする\n",
        "    hist = model.fit(\n",
        "        train_ds_normal,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_ds_normal,\n",
        "        callbacks=default_callback,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # SAVE\n",
        "    os.makedirs(f'{DIR_MODEL_2}', exist_ok=True)\n",
        "    model.save(f'{DIR_MODEL_2}/model.h5')\n",
        "\n",
        "    # Evaluate\n",
        "    test_acc = model.evaluate(test_ds_normal, callbacks=default_callback, verbose=0)\n",
        "  \n",
        "    if plot: plot_history(hist, test_acc).write_image(f\"{DIR_MODEL_2}/model.png\")\n",
        "\n",
        "  elif model_number == 3:\n",
        "    def lrfn(epoch):\n",
        "      start_lr = 0.00001\n",
        "      min_lr = 0.00001\n",
        "      max_lr = 0.00005 * tpu_strategy.num_replicas_in_sync\n",
        "      rampup_epochs = 5\n",
        "      sustain_epochs = 0\n",
        "      exp_decay = .8\n",
        "      if epoch < rampup_epochs: return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "      elif epoch < rampup_epochs + sustain_epochs: return max_lr\n",
        "      else: return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "\n",
        "    fig = go.Figure(data=go.Scatter(x=np.arange(1, num_epochs+1, 1), y=[lrfn(x) for x in np.arange(num_epochs)]))\n",
        "    fig.update_layout(\n",
        "        xaxis=dict(dtick=1),\n",
        "        title='Learning Rate Per Epoch',\n",
        "        yaxis=dict(tickformat=\".5f\"),\n",
        "        title_x=0.5,\n",
        "        xaxis_title='Epoch',\n",
        "        yaxis_title='Learning Rate'\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=1)\n",
        "\n",
        "    # モデルをトレーニングする\n",
        "    hist = model.fit(\n",
        "        train_ds_categorical,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_ds_categorical,\n",
        "        callbacks=default_callback + [lr_callback],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # SAVE\n",
        "    os.makedirs(f'{DIR_MODEL_3}', exist_ok=True)\n",
        "    model.save(f'{DIR_MODEL_3}/model.h5')\n",
        "\n",
        "    # Evaluate\n",
        "    test_acc = model.evaluate(test_ds_categorical, callbacks=default_callback, verbose=0)\n",
        "\n",
        "    if plot: plot_history(hist, test_acc).write_image(f\"{DIR_MODEL_3}/model.png\")\n",
        "  else:\n",
        "    print('Error: Not Defined', file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "MODEL = 1\n",
        "EPOCHS = 10\n",
        "\n",
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "  model = create_model(MODEL)\n",
        "train(MODEL, EPOCHS, True)\n",
        "\n",
        "tf.keras.backend.clear_session() # 計算グラフを破棄する\n",
        "del model                        # 変数を削除する"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESL6ltQTMm05"
      },
      "source": [
        "####評価と予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1w7tPrNPGHK"
      },
      "source": [
        "#保存したモデルを読み込む\n",
        "model = tf.keras.models.load_model('/content/saved_models/TPU/model_3/2021_04_14__00_33_36.h5')\n",
        "test_acc = model.evaluate(test_ds_categorical, verbose=0)\n",
        "# test_acc = model.evaluate(test_ds_normal, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmnr6EBrO79n"
      },
      "source": [
        "#####テストデータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCBgP_oWm6hK"
      },
      "source": [
        "def convert_ds(dataset, n_examples):\n",
        "  return dataset.unbatch().batch(n_examples).as_numpy_iterator()\n",
        "\n",
        "def img_title(label, prediction):\n",
        "  if isinstance(label, np.ndarray):\n",
        "    class_idx = np.argmax(label, axis=-1) # transform from one-hot array to class number\n",
        "    prediction_idx = np.argmax(prediction, axis=-1)\n",
        "    collect = f'Cat: {round(prediction[0]*100)}%, Dog: {round(prediction[1]*100)}%', 'black'\n",
        "    wrong = f'Cat: {round(prediction[0]*100)}%, Dog: {round(prediction[1]*100)}%', 'red'\n",
        "  else:\n",
        "    class_idx = int(label) # transform from one-hot array to class number\n",
        "    prediction_idx = 0 if float(prediction[0]) < 0.5 else 1\n",
        "    collect = f'{round(float(prediction[0]), 3)}', 'black'\n",
        "    wrong = f'{round(float(prediction[0]), 3)}', 'red'\n",
        "  return collect if class_idx == prediction_idx else wrong\n",
        "\n",
        "def get_titles(images, labels, model):\n",
        "  predictions = model.predict(images)\n",
        "  titles, colors = [], []\n",
        "  for label, prediction in zip(classes, predictions):\n",
        "    title, color = img_title(label, prediction)\n",
        "    titles.append(title)\n",
        "    colors.append(color)\n",
        "  return titles, colors\n",
        "\n",
        "converted_ds_categorical = convert_ds(test_ds_categorical, 9)\n",
        "converted_ds_normal = convert_ds(test_ds_normal, 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfKnZqPMrywG"
      },
      "source": [
        "# Re-run this cell to show a new batch of images\n",
        "images, classes = next(converted_ds_categorical)\n",
        "titles, colors = get_titles(images, classes, model)\n",
        "\n",
        "fig = px.imshow(np.squeeze(np.array(images)), facet_col=0, facet_col_wrap=3)\n",
        "fig.for_each_annotation(lambda a: a.update(text=(titles[int(a.text.split(\"=\")[-1])]), bordercolor=\"red\") if colors[int(a.text.split(\"=\")[-1])] == 'red' else a.update(text=(titles[int(a.text.split(\"=\")[-1])])))\n",
        "fig.update_layout(title_x=0.5, title_text=f\"Loss: {round(test_acc[0], 3)}, Acc: {round(test_acc[1]*100)}%\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPpeOWYdO_Y_"
      },
      "source": [
        "#####オリジナルデータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXxCFrKUZucE"
      },
      "source": [
        "CLASSES = ['Cat', 'Dog']\n",
        "\n",
        "file_name = list(files.upload())[0]\n",
        "\n",
        "img = np.asarray(Image.open(file_name).convert('RGB').resize((IMG_SIZE, IMG_SIZE))) / 255.0\n",
        "pred = model.predict(np.array([img]))\n",
        "if len(pred[0]) == 1:\n",
        "  title = f'This is a {CLASSES[0] if pred[0] < 0.5 else CLASSES[1]} ({round(float(pred[0]),3)})'\n",
        "else:\n",
        "  title = f\"This is a {CLASSES[int(np.argmax(pred, axis=1))]} (Cat: {round(pred[0][0]*100)}%, Dog: {round(pred[0][1]*100)}%)\"\n",
        "fig = px.imshow(img)\n",
        "fig.update_layout(\n",
        "    title_x=0.5,\n",
        "    title_text=title\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "os.remove(f'./{file_name}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lyQiZcDOf_z"
      },
      "source": [
        "###GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bZBtvZyEA5B"
      },
      "source": [
        "####モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1BAVOiu-yAa"
      },
      "source": [
        "#####[MobileNetV2](https://www.tensorflow.org/tutorials/images/transfer_learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc48jT4_--zH"
      },
      "source": [
        "DATE_TIME = datetime.datetime.now(pytz.timezone('Asia/Tokyo')).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "DIR_MODEL = f\"saved_models/MobileNetV2/{DATE_TIME}\"\n",
        "\n",
        "os.makedirs(f'{DIR_MODEL}/model_summary', exist_ok=True)\n",
        "os.makedirs(f'{DIR_MODEL}/model_history', exist_ok=True)\n",
        "\n",
        "def plot_history(acc, val_acc, loss, val_loss, epochs, test_acc):\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=loss, name=\"loss\", line = dict(color='royalblue', dash='dash')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=val_loss, name=\"val_loss\", line = dict(color='firebrick', dash='dash')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=acc, name=\"acc\", line=dict(color='royalblue')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=val_acc, name=\"val_acc\", line=dict(color='firebrick')))\n",
        "  fig.update_layout(\n",
        "      xaxis=dict(dtick=1),\n",
        "      title=f'Loss: {round(test_acc[0], 4)} / Accurecy: {round(test_acc[1]*100)}%',\n",
        "      title_x=0.5,\n",
        "      xaxis_title='Epoch',\n",
        "      yaxis_title='Loss/Accuracy'\n",
        "  )\n",
        "  fig.show()\n",
        "  return fig\n",
        "\n",
        "def transfer_learning():\n",
        "  INIT_EPOCS = 1\n",
        "  FINE_EPOCS = 1\n",
        "  BASE_LR = 0.0001\n",
        "\n",
        "  callbacks = [\n",
        "               tfa.callbacks.TQDMProgressBar(),\n",
        "              #  tf.keras.callbacks.TensorBoard(log_dir=f'{DIR_MODEL}/tensorboard',histogram_freq=1),\n",
        "               tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=3, verbose=1),\n",
        "               tf.keras.callbacks.ModelCheckpoint(\n",
        "                   filepath='%s/checkpoints/cp_epoch_{epoch}.ckpt'%DIR_MODEL,\n",
        "                   monitor='val_loss',\n",
        "                   verbose=1,\n",
        "                   save_best_only=True,\n",
        "                   save_weights_only=True\n",
        "               )\n",
        "  ]\n",
        "\n",
        "  # ランダムデータ拡張\n",
        "  data_augmentation = tf.keras.Sequential([\n",
        "                                           tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "                                           tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "                                           ])\n",
        "\n",
        "  # ピクセル値を再スケーリングします\n",
        "  preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "  # 事前にトレーニングされたconvnetからベースモデルを作成します\n",
        "  # input_shapeのサイズは 96, 128, 160, 192, 224\n",
        "  base_model = tf.keras.applications.MobileNetV2(\n",
        "      input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "      include_top=False,\n",
        "      weights='imagenet'\n",
        "  )\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # 分類ヘッドを追加する\n",
        "  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "  prediction_layer = tf.keras.layers.Dense(1)\n",
        "\n",
        "  inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "  x = data_augmentation(inputs)\n",
        "  x = preprocess_input(x)\n",
        "  x = base_model(x, training=False)\n",
        "  x = global_average_layer(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  outputs = prediction_layer(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  # モデルをコンパイルする\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=BASE_LR),\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  model.summary()\n",
        "  tf.keras.utils.plot_model(model, f'{DIR_MODEL}/model_summary/transfer_learning.png', show_shapes=True)\n",
        "\n",
        "  # モデルをトレーニングする\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      epochs=INIT_EPOCS,\n",
        "      validation_data=val_ds,\n",
        "      callbacks=callbacks,\n",
        "      verbose=0,\n",
        "  )\n",
        "  # SavedModel\n",
        "  model.save(f'{DIR_MODEL}/saved_model/transfer_learning')\n",
        "\n",
        "  #テスト\n",
        "  test_acc = model.evaluate(test_ds, callbacks=[tfa.callbacks.TQDMProgressBar()], verbose=0)\n",
        "\n",
        "  #プロット\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  plot_history(acc, val_acc, loss, val_loss, INIT_EPOCS, test_acc).write_image(f\"{DIR_MODEL}/model_history/transfer_learning.png\")\n",
        "\n",
        "  # MobileNet V2の層の数は154でした。\n",
        "  # そのうち100までの重み付けはそのままで、残りの54層の重み付けを再学習することで調整させます。 \n",
        "  base_model.trainable = True\n",
        "  fine_tune_at = 100\n",
        "  for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      optimizer = tf.keras.optimizers.RMSprop(lr=BASE_LR/10),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  history_fine = model.fit(\n",
        "      train_ds,\n",
        "      epochs=INIT_EPOCS+FINE_EPOCS,\n",
        "      initial_epoch=INIT_EPOCS,\n",
        "      validation_data=val_ds,\n",
        "      callbacks=callbacks,\n",
        "      verbose=0,\n",
        "  )\n",
        "\n",
        "  # SavedModel\n",
        "  model.save(f'{DIR_MODEL}/saved_model/fine_tuning')\n",
        "\n",
        "  #テスト\n",
        "  test_acc = model.evaluate(test_ds, callbacks=[tfa.callbacks.TQDMProgressBar()], verbose=0)\n",
        "\n",
        "  #プロット\n",
        "  acc += history.history['accuracy']\n",
        "  val_acc += history.history['val_accuracy']\n",
        "  loss += history.history['loss']\n",
        "  val_loss += history.history['val_loss']\n",
        "  plot_history(acc, val_acc, loss, val_loss, INIT_EPOCS+FINE_EPOCS, test_acc).write_image(f\"{DIR_MODEL}/model_history/fine_tuning.png\")\n",
        "\n",
        "transfer_learning()\n",
        "tf.keras.backend.clear_session() # 計算グラフを破棄する"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLPdMFJm9Bln"
      },
      "source": [
        "#####[Xception](https://www.tensorflow.org/guide/keras/transfer_learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjLBbVPWtJwp"
      },
      "source": [
        "DATE_TIME = datetime.datetime.now(pytz.timezone('Asia/Tokyo')).strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "DIR_MODEL = f\"saved_models/Xception/{DATE_TIME}\"\n",
        "\n",
        "os.makedirs(f'{DIR_MODEL}/model_summary', exist_ok=True)\n",
        "os.makedirs(f'{DIR_MODEL}/model_history', exist_ok=True)\n",
        "\n",
        "def plot_history(acc, val_acc, loss, val_loss, epochs, test_acc):\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=loss, name=\"loss\", line = dict(color='royalblue', dash='dash')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=val_loss, name=\"val_loss\", line = dict(color='firebrick', dash='dash')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=acc, name=\"acc\", line=dict(color='royalblue')))\n",
        "  fig.add_trace(go.Scatter(x=np.arange(1, epochs+1, 1), y=val_acc, name=\"val_acc\", line=dict(color='firebrick')))\n",
        "  fig.update_layout(\n",
        "      xaxis=dict(dtick=1),\n",
        "      title=f'Loss: {round(test_acc[0], 4)} / Accurecy: {round(test_acc[1]*100)}%',\n",
        "      title_x=0.5,\n",
        "      xaxis_title='Epoch',\n",
        "      yaxis_title='Loss/Accuracy'\n",
        "  )\n",
        "  fig.show()\n",
        "  return fig\n",
        "\n",
        "def transfer_learning():\n",
        "  INIT_EPOCS = 1\n",
        "  FINE_EPOCS = 1\n",
        "\n",
        "  callbacks = [\n",
        "               tfa.callbacks.TQDMProgressBar(),\n",
        "              #  tf.keras.callbacks.TensorBoard(log_dir=f'{DIR_MODEL}/tensorboard',histogram_freq=1),\n",
        "               tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=3, verbose=1),\n",
        "               tf.keras.callbacks.ModelCheckpoint(\n",
        "                   filepath='%s/checkpoints/cp_epoch_{epoch}.ckpt'%DIR_MODEL,\n",
        "                   monitor='val_loss',\n",
        "                   verbose=1,\n",
        "                   save_best_only=True,\n",
        "                   save_weights_only=True\n",
        "               )\n",
        "  ]\n",
        "\n",
        "  # ランダムデータ拡張\n",
        "  data_augmentation = tf.keras.Sequential([\n",
        "                                           tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "                                           tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "                                           ])\n",
        "\n",
        "  base_model = tf.keras.applications.Xception(\n",
        "      weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "      input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "      include_top=False,\n",
        "  )  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Create new model on top\n",
        "  inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "  x = data_augmentation(inputs)  # Apply random data augmentation\n",
        "\n",
        "  # Normalizationレイヤーを追加して、入力値（最初は[0, 255]範囲）を[-1, 1] [0, 255]範囲にスケーリングします。\n",
        "  norm_layer = tf.keras.layers.experimental.preprocessing.Normalization() #-1から1までのピクセル値を正規化\n",
        "  mean = np.array([127.5] * 3)\n",
        "  var = mean ** 2\n",
        "  # Scale inputs to [-1, +1]\n",
        "  x = norm_layer(x)\n",
        "  norm_layer.set_weights([mean, var])\n",
        "\n",
        "  # ベースモデルを呼び出すときにtraining=Falseを渡すようにして、推論モードで実行するようにします。これにより、微調整のためにベースモデルのフリーズを解除した後でも、batchnorm統計が更新されません。\n",
        "  x = base_model(x, training=False)\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)  # 正則化のために、分類レイヤーの前にDropoutレイヤーを追加\n",
        "  outputs = tf.keras.layers.Dense(1)(x)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "  #最上層をトレーニングする\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        "  )\n",
        "  model.summary()\n",
        "  tf.keras.utils.plot_model(model, f'{DIR_MODEL}/model_summary/transfer_learning.png', show_shapes=True)\n",
        "\n",
        "  # モデルをトレーニングする\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      epochs=INIT_EPOCS,\n",
        "      validation_data=val_ds,\n",
        "      callbacks=callbacks,\n",
        "      verbose=0,\n",
        "  )\n",
        "\n",
        "  # Save\n",
        "  model.save(f'{DIR_MODEL}/saved_model/transfer_learning')\n",
        "\n",
        "  #テスト\n",
        "  test_acc = model.evaluate(test_ds, callbacks=[tfa.callbacks.TQDMProgressBar()], verbose=0)\n",
        "\n",
        "  #プロット\n",
        "  acc = history.history['binary_accuracy']\n",
        "  val_acc = history.history['val_binary_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  plot_history(acc, val_acc, loss, val_loss, INIT_EPOCS, test_acc).write_image(f\"{DIR_MODEL}/model_history/transfer_learning.png\")\n",
        "\n",
        "  base_model.trainable = True\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
        "  )\n",
        "\n",
        "  history_fine = model.fit(\n",
        "      train_ds,\n",
        "      epochs=INIT_EPOCS+FINE_EPOCS,\n",
        "      initial_epoch=INIT_EPOCS,\n",
        "      validation_data=val_ds,\n",
        "      callbacks=callbacks,\n",
        "      verbose=0,\n",
        "  )\n",
        "\n",
        "  # SavedModel\n",
        "  model.save(f'{DIR_MODEL}/saved_model/fine_tuning')\n",
        "\n",
        "  #テスト\n",
        "  test_acc = model.evaluate(test_ds, callbacks=[tfa.callbacks.TQDMProgressBar()], verbose=0)\n",
        "\n",
        "  #プロット\n",
        "  acc += history.history['binary_accuracy']\n",
        "  val_acc += history.history['val_binary_accuracy']\n",
        "  loss += history.history['loss']\n",
        "  val_loss += history.history['val_loss']\n",
        "  plot_history(acc, val_acc, loss, val_loss, INIT_EPOCS+FINE_EPOCS, test_acc).write_image(f\"{DIR_MODEL}/model_history/fine_tuning.png\")\n",
        "\n",
        "transfer_learning()\n",
        "tf.keras.backend.clear_session() # 計算グラフを破棄する"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fPsQKPtEQQD"
      },
      "source": [
        "####評価と予測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGM58zdNEQQF"
      },
      "source": [
        "#保存したモデルを読み込む\n",
        "model = tf.keras.models.load_model('/content/saved_models/Xception/2021-04-16_01:37:16/saved_model/fine_tuning')\n",
        "test_acc = model.evaluate(test_ds, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMK3kthNEQQG"
      },
      "source": [
        "#####テストデータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFxHfAEoGQOj"
      },
      "source": [
        "#Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
        "pred = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "# Apply a sigmoid since our model returns logits\n",
        "pred = tf.nn.sigmoid(pred)\n",
        "pred_label = tf.where(pred < 0.5, 0, 1)\n",
        "pred = [round(float(x), 3) for x in pred]\n",
        "\n",
        "fig = px.imshow(\n",
        "    np.squeeze(np.array(image_batch[:9])),\n",
        "    facet_col=0,\n",
        "    facet_col_wrap=3\n",
        ")\n",
        "fig.for_each_annotation(\n",
        "    lambda a: a.update(text=(f'{pred[int(a.text.split(\"=\")[-1])]}'), bordercolor=\"red\") if pred_label[int(a.text.split(\"=\")[-1])] != label_batch[int(a.text.split(\"=\")[-1])] else a.update(text=(f'{pred[int(a.text.split(\"=\")[-1])]}'))\n",
        ")\n",
        "fig.update_layout(\n",
        "    title_x=0.5,\n",
        "    title_text=f\"Loss: {round(test_acc[0], 3)}, Acc: {round(test_acc[1]*100)}%\"\n",
        ")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRADGoRIEQQJ"
      },
      "source": [
        "#####オリジナルデータ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_1m2LCmEQQJ"
      },
      "source": [
        "CLASSES = ['Cat', 'Dog']\n",
        "\n",
        "file_name = list(files.upload())[0]\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(\n",
        "    file_name, target_size=(IMG_SIZE, IMG_SIZE)\n",
        ")\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "pred = model.predict(img_array)\n",
        "pred = tf.nn.sigmoid(pred)\n",
        "\n",
        "title = f'This is a {CLASSES[0] if pred[0] < 0.5 else CLASSES[1]} ({round(float(pred[0]),3)})'\n",
        "\n",
        "fig = px.imshow(img)\n",
        "fig.update_layout(\n",
        "    title_x=0.5,\n",
        "    title_text=title\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "os.remove(f'./{file_name}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfEDNI9u9TKk"
      },
      "source": [
        "## メモ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PK7ZvwEx3qh"
      },
      "source": [
        "###TFRecords読み込む"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waUl9CRv2RvD"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "IMG_SIZE = 160\n",
        "batch_size = 16 * strategy.num_replicas_in_sync\n",
        "\n",
        "train_fns = os.listdir('/content/datasets/v1/tfrecords/train')\n",
        "validation_fns = os.listdir('/content/datasets/v1/tfrecords/val')\n",
        "        \n",
        "def parse_tfrecord(example):\n",
        "  features = {\n",
        "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "    \"one_hot_class\": tf.io.VarLenFeature(tf.float32),\n",
        "  } \n",
        "  example = tf.io.parse_single_example(example, features)\n",
        "  decoded = tf.image.decode_jpeg(example['image_raw'], channels=3)\n",
        "  normalized = tf.cast(decoded, tf.float32) / 255.0 # convert each 0-255 value to floats in [0, 1] range\n",
        "  image_tensor = tf.reshape(normalized, [*[IMG_SIZE, IMG_SIZE], 3])\n",
        "  one_hot_class = tf.reshape(tf.sparse.to_dense(example['one_hot_class']), [2])\n",
        "  return image_tensor, one_hot_class\n",
        "\n",
        "def load_dataset(filenames):\n",
        "  # Read from TFRecords. For optimal performance, we interleave reads from multiple files.\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "  return records.map(parse_tfrecord, num_parallel_calls=AUTO)\n",
        "\n",
        "def get_training_dataset():\n",
        "  dataset = load_dataset(train_fns)\n",
        "\n",
        "  # Create some additional training images by randomly flipping and\n",
        "  # increasing/decreasing the saturation of images in the training set. \n",
        "  def data_augment(image, one_hot_class):\n",
        "    modified = tf.image.random_flip_left_right(image)\n",
        "    modified = tf.image.random_saturation(modified, 0, 2)\n",
        "    return modified, one_hot_class\n",
        "  augmented = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "\n",
        "  # Prefetch the next batch while training (autotune prefetch buffer size).\n",
        "  return augmented.repeat().shuffle(2048).batch(batch_size).prefetch(AUTO) \n",
        "\n",
        "train_ds = get_training_dataset()\n",
        "val_ds = load_dataset(validation_fns).batch(batch_size).prefetch(AUTO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ztw2VjnwSO5"
      },
      "source": [
        "###TFRecords作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dwCx59OuHml"
      },
      "source": [
        "os.makedirs('/content/datasets/v1/tfrecords/train', exist_ok=True)\n",
        "os.makedirs('/content/datasets/v1/tfrecords/test', exist_ok=True)\n",
        "os.makedirs('/content/datasets/v1/tfrecords/val', exist_ok=True)\n",
        "\n",
        "CLASSES = ['cat', 'dog']\n",
        "\n",
        "# 下記の関数を使うと値を tf.Example と互換性の有る型に変換できる\n",
        "def _bytes_feature(value):\n",
        "  \"\"\"string / byte 型から byte_list を返す\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"float / double 型から float_list を返す\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"bool / enum / int / uint 型から Int64_list を返す\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "# 関連する特徴量のディクショナリを作成\n",
        "def image_example(image_string, label):\n",
        "  image_shape = tf.image.decode_jpeg(image_string).shape\n",
        "  one_hot_class = np.eye(len(CLASSES))[label]\n",
        "  \n",
        "  feature = {\n",
        "      'height': _int64_feature(image_shape[0]),\n",
        "      'width': _int64_feature(image_shape[1]),\n",
        "      'depth': _int64_feature(image_shape[2]),\n",
        "      'label': _int64_feature(label_train),\n",
        "      'image_raw': _bytes_feature(image_string),\n",
        "      \"one_hot_class\": _float_feature(one_hot_class.tolist())\n",
        "  }\n",
        "\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "# train\n",
        "for img_train, label_train in zip(v1_all_imgs_train, v1_all_labels_train):\n",
        "  file_name = os.path.splitext(os.path.basename(img_train))[0]\n",
        "  with tf.io.TFRecordWriter(f'/content/datasets/v1/tfrecords/train/{file_name}.tfrec') as writer:\n",
        "    image_string = open(img_train, 'rb').read()\n",
        "    tf_example = image_example(image_string, label_train)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "# val\n",
        "for img_val, label_val in zip(v1_all_imgs_val, v1_all_labels_val):\n",
        "  file_name = os.path.splitext(os.path.basename(img_val))[0]\n",
        "  with tf.io.TFRecordWriter(f'/content/datasets/v1/tfrecords/val/{file_name}.tfrec') as writer:\n",
        "    image_string = open(img_val, 'rb').read()\n",
        "    tf_example = image_example(image_string, label_val)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "# test\n",
        "for img_test, label_test in zip(v1_all_imgs_test, v1_all_labels_test):\n",
        "  file_name = os.path.splitext(os.path.basename(img_test))[0]\n",
        "  with tf.io.TFRecordWriter(f'/content/datasets/v1/tfrecords/test/{file_name}.tfrec') as writer:\n",
        "    image_string = open(img_test, 'rb').read()\n",
        "    tf_example = image_example(image_string, label_test)\n",
        "    writer.write(tf_example.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwfRyZBkoUHA"
      },
      "source": [
        "###colabで35GBメモリを無料で利用する方法\n",
        "\n",
        "1. ipynbファイルをダウンロード\n",
        "2. ダウンロードしたファイルを編集\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"name\": \"Untitled2.ipynb\",\n",
        "      \"provenance\": [],\n",
        "      \"machine_shape\": \"hm\" <---追加\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"accelerator\": \"TPU\"\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "```\n",
        "3. アップロードして開く\n"
      ]
    }
  ]
}